"""
Script.

Compare how quickly different 'dF' (multicanonical/transition matrix) simulations converge on
a result for the free energy difference between the two lattices.

Input data is generated by running      ./get_data.sh dF    in an appropriate directory.

Note that multiple simulations with the same simID (set in params.py) will be averaged over,
rather than compared.

Argument variables give the type of comparison to make:
No argument variable: Compares the values and uncertainties on dF for different simulations.
                      They must have run for the same number of sweeps!
                      Input file = "dF_data.txt"

argv[1] == 'std': Compare standard deviation as a function of sweeps for different simulations.
                  Input file = "stdev_series.txt"

argv[1] == 'psi': Compute the speedup function.
                  Input file = "stdev_series.txt"

Run as e.g.     python compare_dF.py std
"""

import numpy as np
import matplotlib.pyplot as plt
from sys import argv, exit

# Import information on input files, simulation data from sim_info.py (make sure it's correct!)
import sim_info

window = 5

# Generic plot parameters
plt.rc('text', usetex=True)
font = {'family' : 'serif',
        'size' : 14}
plt.rc('font', **font)
colors = ('b', 'g', 'm', 'c')

# Create plot
fig, ax = plt.subplots()
ax.tick_params(direction='in', top=True, right=True)
ax.set_xlabel(r"$\sqrt{Ns}$")
ax.set_ylabel(r"$\psi$")
ax.set_title("Speedup function")

# Input file names given as arguments
input_files = argv[1:]
Nfiles = len(input_files)

# Quick check
if Nfiles == 0:
    print "Error: Please provide one or more input files as arguments"
    exit(1)


# Iterate over input files
for ifile in range(Nfiles):

    # Initialise lists
    simID = []
    Ns = []
    dF_stdev = []
    sweeps_per_s = []
    
    # Read input data
    print "Reading data fom file ", input_files[ifile]
    input_data = np.loadtxt(input_files[ifile])
    
    # Look for lines with Ns = -1 in second col
    # These separate data from different simulations
    new_sim_rows = np.where( input_data[:,1] == -1 )[0]
    Nsim = len(new_sim_rows)

    # Separate data from different simulations 
    rlo = 0
    for i in range(Nsim):
        rhi = int(new_sim_rows[i])
        
        simID.append(input_data[rlo,0])
        Ns.append(input_data[rlo,1])
        sweeps_per_s.append(input_data[rlo+1:rhi,0])
        dF_stdev.append(input_data[rlo+1:rhi,1])

        rlo = rhi + 1

    # Maybe we calculate speed relative to Np =/= 1 processors
    min_Ns = np.min(Ns)
    print "Computing speedup function defined as:  psi(Np) = X(%d)/X(Np),  (X: sweeps)" %min_Ns

    # Find the smallest std dev which all simulations have converged to 
    convergence = []
    for sim in range(Nsim):
        # Take mean of the last 'window' std devs as the level of convergence
        convergence.append( np.mean(dF_stdev[sim][-window:]) )
    stdev_to_compare = np.max(convergence)
    print "Comparing number of sweeps taken to achieve a standard deviation on dF of %f" %stdev_to_compare

    # Find the number of sweeps each sim has taken to achieve this standard deviation
    Nsweeps_converged = []
    for sim in range(Nsim):

        # Work backwards to hopefully avoid flukey early convergence followed by divergence
        for i in range(len(dF_stdev[sim]) - window):
            this_mean = np.mean(dF_stdev[sim][-i-window:-i])
            if this_mean > stdev_to_compare:
                Nsweeps_converged.append( sweeps_per_s[sim][-i+1] )
                break

    # Initialise lists to hold averages over repeats + unique values
    Nsweeps_converged_mean = []
    Nsweeps_converged_stderr = []
    unique_Ns = []
    N_repeats_list = []
    unique_simID = np.sort(np.array(list(set(simID)), dtype=int)) # low->high simID
    simID = np.array(simID, dtype=int) # convert to int for usid == sid expression

    # ----------------------------- #
    #  Iterate over unique simID's  #
    # ----------------------------- #
    for usid in unique_simID:

        # Find indices corresponding to repeats to be averaged over
        index_list = [i for i, sid in enumerate(simID) if usid == sid]
        index_list = np.array(index_list)
        i0 = index_list[0] 
        
        # Keep track of the number of sims we're averaging over
        N_repeats = len(index_list)
        N_repeats_list.append(N_repeats)
        print "Averaging over %d simulations for simID: %d (%s)" \
                %(N_repeats, usid, sim_info.sim_labels[usid])

        # Assume repeats have same Ns - pretty safe to assume
        unique_Ns.append(Ns[i0])
            
        # Pull out values for sims with this simID
        data_to_average = Nsweeps_converged[ index_list ]

        # Take mean and standard error
        Nsweeps_converged_mean.append(np.mean(data_to_average))
        Nsweeps_converged_stderr.append(np.std(data_to_average) / np.sqrt(N_repeats))


    # End loop over unique simID's


    # Rename things for convenience and convert to arrays of ints
    Ns = np.array(unique_Ns, dtype=int)
    simID = np.array(unique_simID, dtype=int)
    Nsim = len(simID) # now this is number of sims after averaging

    # Compute speedup function
    Nsweeps_converged_mean = np.array(Nsweeps_converged_mean)
    sweeps_serial = Nsweeps_converged_mean[ Ns==min_Ns ]
    psi = np.ones(Nsim)*sweeps_serial / Nsweeps_converged_mean
        
    # Compute uncertainty on speedup functioin by propagating the uncertainty
    # on the mean sweeps using the functional approach
    psi_plus_err = np.ones(Nsim)*sweeps_serial / \
                (Nsweeps_converged_mean + Nsweeps_converged_stderr)
    psi_err = np.abs(psi - psi_plus_err)

    # Compute fit parameters
    coeffs = np.polyfit(Ns, psi, 1)
    fit = Ns*coeffs[0] + coeffs[1]


    # ------------- #
    #  Add to plot  #
    # ------------- #

    # Add text to show the standard deviation
    rootNs = np.sqrt(Ns)
    coords = (rootNs[0], np.max(psi+0.5*psi_err))
    ax.text(coords[0], coords[1], \
            "Comparing sweeps to \nreach $\sigma=$ %1.1e" %stdev_to_compare)

    # Input file is a key to acccess dictionary, value describes the simulation
    label = sim_info.file_labels[ input_files[ifile] ]

    # Plot data
    ax.errorbar(rootNs, psi, yerr=psi_err, fmt=colors[ifile]+'o', label=label)
    ax.plot(rootNs, fit, 'r--')


# End loop over input files


ax.legend()
plt.tight_layout()
plt.show()

